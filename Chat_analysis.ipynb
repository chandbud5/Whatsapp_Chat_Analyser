{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whatsapp Chat analysis\n",
    "\n",
    "#### Export chats which you want to analyse, in txt format file\n",
    "Every line in this txt file will consists a msg sent by a user. Format of each line is of the form {date}, {time} - {sender}: {Message}\n",
    "\n",
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will fetch the date and time when message was sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdate(ip):\n",
    "    # We will use regex to get date from txt file\n",
    "    date = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9])([0-9]), ([0-9]+):([0-9][0-9]) (am|pm) - '\n",
    "    op = re.match(date, ip)\n",
    "    if op:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "# Just to verify our function implementation is correct\n",
    "print(getdate(\"01/02/20, 1:44 pm - \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the sender of a message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sender(ip):\n",
    "    user = [\"([\\w]+):\", \"([\\w]+)+([\\s])+([\\w]+):\", \"([\\w]+)+([\\s])+([\\w]+)+([\\s])+([\\w]+):\",\n",
    "            \"([+]\\d{2} \\d{5} \\d{5}):\", '([\\w]+)[\\u263a-\\U0001f999]+:']\n",
    "\n",
    "    # The expression at index 3 is for mobile numbers from India\n",
    "    # while the one at 4 th position is for any name and emoji\n",
    "\n",
    "    user = \"^\" +  \"|\".join(user)\n",
    "    op = re.match(user, ip)\n",
    "\n",
    "    if op:\n",
    "        return True\n",
    "    return False\n",
    "# Check it's implementation\n",
    "print(sender(\"ABC: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get message and data by putting all together\n",
    "def data(l):\n",
    "    line = l.split(\" - \")\n",
    "    print(line)\n",
    "    date_time = line[0]\n",
    "    txt = \" \".join(line[1:])    # txt consists author and message\n",
    "    dt, time = date_time.split(\", \")    # dt has date and time has time when msg was sent\n",
    "    message = \" \".join(line[1:])\n",
    "    if sender(txt):\n",
    "        msg = txt.split(\": \")\n",
    "        user = msg[0]\n",
    "        print(msg)\n",
    "        message = \" \".join(msg[1:])\n",
    "    else:\n",
    "        user = None\n",
    "\n",
    "    return dt, time, user, message\n",
    "\n",
    "dt, time, user, me = data(\"01/02/20, 1:56 pm - ABC: Hey, every one I welcome you all\")\n",
    "print(dt)\n",
    "print(time)\n",
    "print(user)\n",
    "print(me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating dataframe from our txt file\n",
    "\n",
    "### Creating lists from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data = []\n",
    "txt_file = \"chat_m.txt\"\n",
    "\n",
    "with open(txt_file, encoding=\"utf-8\") as f:\n",
    "    # skipping the first encryption line\n",
    "    f.readline()\n",
    "    messages = []\n",
    "    date, time, user = [], [], []\n",
    "    line = f.readlines()\n",
    "\n",
    "    for i in line:\n",
    "            \n",
    "        if getdate(i):\n",
    "            p = i.split(\" - \")\n",
    "            if sender(p[1]):\n",
    "                dt, t, u, mess = data(i)              \n",
    "                messages.append(mess)\n",
    "                date.append(dt)\n",
    "                time.append(t)\n",
    "                user.append(u)\n",
    "            else:\n",
    "                x = i.split(\" - \")\n",
    "                dt = x[0]\n",
    "                msg = x[1:]\n",
    "                messages.append(\" \".join(msg))\n",
    "                dt = dt.split(\", \")\n",
    "                dt, t = dt[0], dt[1]\n",
    "                date.append(dt)\n",
    "                user.append(None)\n",
    "                time.append(t)\n",
    "        else:\n",
    "            messages[-1]+=i\n",
    "print(\"Total number of messages including media content\",len(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing media content\n",
    "also remove unnecessary newline character i.e. \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_msg, clean_u, clean_dt, clean_t = [], [], [], []\n",
    "\n",
    "for i in range(len(messages)):\n",
    "    if messages[i]!='<Media omitted>\\n':\n",
    "        clean_msg.append(messages[i][:-1].replace(\"\\n\", \" \"))\n",
    "        clean_u.append(user[i])\n",
    "        clean_dt.append(date[i])\n",
    "        clean_t.append(time[i])\n",
    "    \n",
    "print(len(clean_t))\n",
    "print(len(clean_dt))\n",
    "print(len(clean_u))\n",
    "print(\"After cleaning total number of messages\",len(clean_msg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(clean_dt, clean_t, clean_u, clean_msg)), columns=[\"Date\", \"Time\", \"Sender\", \"Message\"])\n",
    "print(df.shape)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Emoji's from a message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_list = []\n",
    "def emoji_count(text, emoji_list=[]):\n",
    "    text = text.split(\" \")\n",
    "    for word in text:\n",
    "        for i in word:\n",
    "            if i in emoji.UNICODE_EMOJI:\n",
    "                emoji_list.append(i)\n",
    "    return emoji_list\n",
    "\n",
    "print(emoji_count('üòç BFF ‚ù§Ô∏èüòç‚ù§Ô∏è BFF üòç\"',[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all emojis from all messages\n",
    "emo = []\n",
    "for i in clean_msg:\n",
    "    emoji_count(i, emo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_df = pd.DataFrame(emo, columns=[\"Emoji\"])\n",
    "emoji_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_df[\"Emoji\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Chat Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Messages\", len(messages))\n",
    "print(\"Total Media messages\", len(messages)-len(clean_msg))\n",
    "print(\"Total Number of Emojis used\", len(emo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will add another column for word count and Char count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Char_Count'] = df['Message'].apply(lambda s : len(s))\n",
    "df['Word_Count'] = df['Message'].apply(lambda s : len(s.split(' ')))\n",
    "df['Emoji Used'] = df['Message'].apply(lambda s: emoji_count(s,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sender Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all participants of a group\n",
    "senders = df[\"Sender\"].unique()\n",
    "p = list(senders)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df[\"Message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(p)):\n",
    "    s_df = df.loc[df[\"Sender\"]==p[i]]\n",
    "    print(\"Stats of \",p[i])\n",
    "    print(\"Total Messages sent by {} is {}\".format(p[i],s_df.shape[0]))\n",
    "    msg = list(s_df[\"Message\"])\n",
    "    avg_c = s_df.mean()[0]\n",
    "    avg_w = s_df.mean()[1]\n",
    "    print(\"Average size of message sent by {} is {} words or {} characters\".format(p[i], int(avg_w), int(avg_c)))\n",
    "    \n",
    "    # finding total number of emoji sent by individual participant\n",
    "    e = []\n",
    "    for j in msg:\n",
    "        e = emoji_count(j, e)\n",
    "    \n",
    "    print(\"Total Number of Emoji sent by {} is {}\".format(p[i],len(e)))\n",
    "    \n",
    "    edf = pd.DataFrame(e,columns=[\"Emoji\"])\n",
    "    a = edf.describe()\n",
    "    freq_em = a[\"Emoji\"][2]\n",
    "    freq = a[\"Emoji\"][3]\n",
    "    print(\"Most frequently used emoji by {} is {}.\\n{} used {} for {} times\".format(p[i], freq_em, p[i], freq_em, freq))\n",
    "    print(edf[\"Emoji\"].value_counts())\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(review for review in df.Message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import STOPWORDS, WordCloud\n",
    "#stopwords = list(STOPWORDS)\n",
    "stopwords = [\"ha\", \"Hu\", \"tu\", \"na\", \"ne\", \"eni\", \"ma\", \"to\",\"toh\", \"Ok\", \"su\", \"nai\", \"thi\", \"che\", \"This\", \"deleted\", \"message\", \"Aa\", \"ni\"]\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "  \n",
    "plt.figure( figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
